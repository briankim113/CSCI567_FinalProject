{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "RHQDx6rP5bsG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHQDx6rP5bsG",
    "outputId": "e72f12a1-2b47-4a41-bbbe-789575b7a47b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping lightgbm as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip uninstall lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "RX07OiGl5HZo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RX07OiGl5HZo",
    "outputId": "1e937365-208c-4c82-81be-d768e20ec33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option / --install-option. Consider using --config-settings for more flexibility.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: --install-option is deprecated because it forces pip to use the 'setup.py install' command which is itself deprecated. pip 23.1 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11358\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting lightgbm\n",
      "  Using cached lightgbm-3.3.5.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm) (0.40.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.22.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Installing collected packages: lightgbm\n",
      "\u001b[33m  DEPRECATION: lightgbm is being installed using the legacy 'setup.py install' method, because the '--no-binary' option was enabled for it and this currently disables local wheel building for projects that don't have a 'pyproject.toml' file. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/11451\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for lightgbm ... \u001b[?25l\u001b[?25hdone\n",
      "Successfully installed lightgbm-3.3.5\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm --install-option=--gpu --install-option=\"--opencl-include-dir=/usr/local/cuda/include/\" --install-option=\"--opencl-library=/usr/local/cuda/lib64/libOpenCL.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5973c80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5973c80",
    "outputId": "95b781d9-ae62-4977-b8d0-feb426010f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.4.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: six in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (5.14.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.23.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (3.0.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (4.32.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (9.1.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1\n",
      "[notice] To update, run: C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.23.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1\n",
      "[notice] To update, run: C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.23.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1\n",
      "[notice] To update, run: C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1\n",
      "[notice] To update, run: C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (1.10.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (1.23.4)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optuna) (2.0.7)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.3.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from colorlog->optuna) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# #!{sys.executable} -m pip install catboost\n",
    "# %pip install catboost\n",
    "# %pip install xgboost\n",
    "# %pip install lightgbm\n",
    "# %pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7LN3H8ArwQYn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LN3H8ArwQYn",
    "outputId": "1c208c86-d8e9-45ef-ae81-64924a99ca5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: mlxtend in /usr/local/lib/python3.9/dist-packages (0.14.0)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (3.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.2.2)\n",
      "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.22.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from mlxtend) (67.6.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (5.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=1.5.1->mlxtend) (4.39.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.17.1->mlxtend) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=1.5.1->mlxtend) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=1.5.1->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "WT5s48dhyoKM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WT5s48dhyoKM",
    "outputId": "86b99601-dc8b-46b2-ba3d-07b52cad3bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f8a69c",
   "metadata": {
    "id": "92f8a69c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#import six\n",
    "#sys.modules['sklearn.externals.six'] = six\n",
    "#import joblib\n",
    "import sys\n",
    "from sklearn.metrics import f1_score\n",
    "#sys.modules['sklearn.externals.joblib'] = joblib\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#pd.set_option('display.max_columns', 38)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd51ae1",
   "metadata": {},
   "source": [
    "#### Reading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f346a93",
   "metadata": {
    "id": "9f346a93"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data')\n",
    "train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800bcd69",
   "metadata": {
    "id": "800bcd69"
   },
   "outputs": [],
   "source": [
    "cat_cols=['geo_level_1_id','geo_level_2_id','geo_level_3_id','land_surface_condition', 'foundation_type', 'roof_type',\n",
    "       'ground_floor_type', 'other_floor_type', 'position',\n",
    "       'plan_configuration', 'legal_ownership_status','count_floors_pre_eq', 'has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "       'has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick',\n",
    "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
    "       'legal_ownership_status', 'has_secondary_use',\n",
    "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
    "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "       'has_secondary_use_use_police', 'has_secondary_use_other']\n",
    "\n",
    "selected_features = ['foundation_type',\n",
    "                     'land_surface_condition',\n",
    "                     'roof_type',\n",
    "                    'ground_floor_type',\n",
    "                    'other_floor_type',\n",
    "                    'position',\n",
    "                    'plan_configuration',\n",
    "                    'legal_ownership_status']\n",
    "\n",
    "train_values_subset = train_values[selected_features]\n",
    "train_values_subset = pd.get_dummies(train_values_subset)\n",
    "merged_data = pd.concat([train_values, train_values_subset], axis='columns')\n",
    "#merged_data.drop(selected_features, axis='columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aocVdTokzWca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "aocVdTokzWca",
    "outputId": "df7b2e0a-7444-4bfa-9112-065fa4ba1915"
   },
   "outputs": [],
   "source": [
    "#merged_data\n",
    "merged_data.drop(selected_features, axis='columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb352831",
   "metadata": {
    "id": "eb352831",
    "outputId": "9feb650d-640e-4672-c37a-e22d11d727e8"
   },
   "outputs": [],
   "source": [
    "# print(format('How to find optimal parameters for CatBoost using GridSearchCV for Classification','*^82'))   \n",
    "# # Split the training data set\n",
    "# X = train_values; y = train_labels\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "# #Initialise the catboost classifier, if you have no GPU on your machine you can remove task_type=\"GPU\" \n",
    "# model = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols)\n",
    "\n",
    "# #Choose parameters to test here\n",
    "# parameters = {'depth':[2,4,6,8,10,12],\n",
    "#             'iterations':[10,100,500,1000,5000],\n",
    "#             'learning_rate':[0.02,0.05,0.06,0.07], \n",
    "#             'l2_leaf_reg':[3,5,7,9],\n",
    "#             'border_count':[11,13,15,17]}\n",
    "# print('Paramaters defined')\n",
    "\n",
    "# #Initialise the Gridsearch, cv is set to 2 for speed.\n",
    "# randm = GridSearchCV(estimator=model, param_grid = parameters,cv = 2, verbose = 2)\n",
    "# randm.fit(X_train, y_train, verbose = 0)\n",
    "\n",
    "# # Results from Random Search\n",
    "# print(\"\\n========================================================\")\n",
    "# print(\" Results from Random Search \" )\n",
    "# print(\"========================================================\")    \n",
    "\n",
    "# print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "#       randm.best_estimator_)\n",
    "\n",
    "# print(\"\\n The best score across ALL searched params:\\n\",\n",
    "#       randm.best_score_)\n",
    "\n",
    "# print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "#       randm.best_params_)\n",
    "\n",
    "# print(\"\\n ========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41cea1a",
   "metadata": {
    "id": "e41cea1a"
   },
   "outputs": [],
   "source": [
    "# merged_data_new = merged_data[['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
    "#        'count_floors_pre_eq', 'age', 'has_superstructure_mud_mortar_stone',\n",
    "#        'has_superstructure_mud_mortar_brick',\n",
    "#        'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "#        'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "#        'has_secondary_use', 'has_secondary_use_gov_office',\n",
    "#        'foundation_type_r', 'foundation_type_w', 'land_surface_condition_t',\n",
    "#        'roof_type_n', 'roof_type_x', 'ground_floor_type_f',\n",
    "#        'legal_ownership_status_a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead1e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# for preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# the model\n",
    "#model = xgb.XGBClassifier()\n",
    "from sklearn.decomposition import PCA\n",
    "# for combining the preprocess with model training\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# for optimizing the hyperparameters of the pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9ce6b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 23:12:06,447]\u001b[0m Trial 247 finished with value: 0.747783009274715 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.82, 'xgbclassifier_colsample_bytree': 0.43000000000000005, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1, 'xgbclassifier_lambda': 1.3800000000000001}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:13:50,077]\u001b[0m Trial 248 finished with value: 0.7467315935088507 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.8, 'xgbclassifier_colsample_bytree': 0.44000000000000006, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.08, 'xgbclassifier_lambda': 1.3800000000000001}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:15:28,367]\u001b[0m Trial 249 finished with value: 0.7473570707710254 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.82, 'xgbclassifier_colsample_bytree': 0.47, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1, 'xgbclassifier_lambda': 1.32}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:17:05,982]\u001b[0m Trial 250 finished with value: 0.7474760265693531 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.8099999999999999, 'xgbclassifier_colsample_bytree': 0.44000000000000006, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 30, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1400000000000001, 'xgbclassifier_lambda': 1.34}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:19:02,048]\u001b[0m Trial 251 finished with value: 0.7473493962033914 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.8099999999999999, 'xgbclassifier_colsample_bytree': 0.49, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 30, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1400000000000001, 'xgbclassifier_lambda': 1.34}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:20:40,456]\u001b[0m Trial 252 finished with value: 0.7471767184316254 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.78, 'xgbclassifier_colsample_bytree': 0.43000000000000005, 'xgbclassifier_colsample_bylevel': 0.99, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.08, 'xgbclassifier_lambda': 1.3800000000000001}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:22:23,510]\u001b[0m Trial 253 finished with value: 0.7471959048507104 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.83, 'xgbclassifier_colsample_bytree': 0.45999999999999996, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 30, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.12, 'xgbclassifier_lambda': 1.4000000000000001}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:24:00,938]\u001b[0m Trial 254 finished with value: 0.74693880683497 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.8099999999999999, 'xgbclassifier_colsample_bytree': 0.43000000000000005, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.06, 'xgbclassifier_lambda': 1.28}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:25:31,007]\u001b[0m Trial 255 finished with value: 0.7476487043411192 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.84, 'xgbclassifier_colsample_bytree': 0.44000000000000006, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.060000000000000005, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1400000000000001, 'xgbclassifier_lambda': 1.36}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:27:05,680]\u001b[0m Trial 256 finished with value: 0.7469196204158849 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.83, 'xgbclassifier_colsample_bytree': 0.45000000000000007, 'xgbclassifier_colsample_bylevel': 0.97, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.060000000000000005, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1400000000000001, 'xgbclassifier_lambda': 1.34}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:28:40,760]\u001b[0m Trial 257 finished with value: 0.7470999727552848 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.79, 'xgbclassifier_colsample_bytree': 0.44000000000000006, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.060000000000000005, 'xgbclassifier_max_depth': 30, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1, 'xgbclassifier_lambda': 1.4200000000000002}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:30:17,383]\u001b[0m Trial 258 finished with value: 0.7475182366913405 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.84, 'xgbclassifier_colsample_bytree': 0.43000000000000005, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1600000000000001, 'xgbclassifier_lambda': 1.3}. Best is trial 213 with value: 0.7479556870464809.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:31:57,510]\u001b[0m Trial 259 finished with value: 0.7479940598846513 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.85, 'xgbclassifier_colsample_bytree': 0.45999999999999996, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1600000000000001, 'xgbclassifier_lambda': 1.3}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:33:39,318]\u001b[0m Trial 260 finished with value: 0.7475566095295106 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.84, 'xgbclassifier_colsample_bytree': 0.47, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1600000000000001, 'xgbclassifier_lambda': 1.3}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:35:09,093]\u001b[0m Trial 261 finished with value: 0.7465589157370847 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.82, 'xgbclassifier_colsample_bytree': 0.48, 'xgbclassifier_colsample_bylevel': 0.72, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1600000000000001, 'xgbclassifier_lambda': 1.3}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 23:36:48,753]\u001b[0m Trial 262 finished with value: 0.7474107927444638 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.84, 'xgbclassifier_colsample_bytree': 0.45999999999999996, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1600000000000001, 'xgbclassifier_lambda': 1.26}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:38:51,835]\u001b[0m Trial 263 finished with value: 0.7471920675668935 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.84, 'xgbclassifier_colsample_bytree': 0.53, 'xgbclassifier_colsample_bylevel': 0.97, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.04, 'xgbclassifier_lambda': 1.36}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:40:33,954]\u001b[0m Trial 264 finished with value: 0.7474568401502681 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.8, 'xgbclassifier_colsample_bytree': 0.45000000000000007, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 30, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1, 'xgbclassifier_lambda': 1.24}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:40:40,570]\u001b[0m Trial 265 finished with value: 0.6566168203498836 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.84, 'xgbclassifier_colsample_bytree': 0.48, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 4, 'xgbclassifier_alpha': 1.0, 'xgbclassifier_lambda': 1.34}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:41:44,038]\u001b[0m Trial 266 finished with value: 0.742284181564921 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.8099999999999999, 'xgbclassifier_colsample_bytree': 0.43000000000000005, 'xgbclassifier_colsample_bylevel': 0.51, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1800000000000002, 'xgbclassifier_lambda': 1.4000000000000001}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:43:25,031]\u001b[0m Trial 267 finished with value: 0.7468927594291657 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.85, 'xgbclassifier_colsample_bytree': 0.45999999999999996, 'xgbclassifier_colsample_bylevel': 0.96, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.12, 'xgbclassifier_lambda': 1.2}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:44:56,949]\u001b[0m Trial 268 finished with value: 0.7474299791635489 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.77, 'xgbclassifier_colsample_bytree': 0.44000000000000006, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.060000000000000005, 'xgbclassifier_max_depth': 30, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1800000000000002, 'xgbclassifier_lambda': 1.3800000000000001}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:46:36,841]\u001b[0m Trial 269 finished with value: 0.7465972885752549 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.82, 'xgbclassifier_colsample_bytree': 0.5, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.060000000000000005, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1400000000000001, 'xgbclassifier_lambda': 1.3}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:48:13,539]\u001b[0m Trial 270 finished with value: 0.7473877690415617 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.85, 'xgbclassifier_colsample_bytree': 0.42000000000000004, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.08, 'xgbclassifier_lambda': 1.34}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:49:45,612]\u001b[0m Trial 271 finished with value: 0.7468160137528251 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.8, 'xgbclassifier_colsample_bytree': 0.42000000000000004, 'xgbclassifier_colsample_bylevel': 0.96, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.060000000000000005, 'xgbclassifier_max_depth': 30, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1800000000000002, 'xgbclassifier_lambda': 1.4200000000000002}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:51:27,368]\u001b[0m Trial 272 finished with value: 0.7477177754498255 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.84, 'xgbclassifier_colsample_bytree': 0.44000000000000006, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.06, 'xgbclassifier_lambda': 1.3}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:53:03,615]\u001b[0m Trial 273 finished with value: 0.7473033487975872 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.84, 'xgbclassifier_colsample_bytree': 0.45999999999999996, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.060000000000000005, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.06, 'xgbclassifier_lambda': 1.24}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:54:48,953]\u001b[0m Trial 274 finished with value: 0.7476909144631065 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.83, 'xgbclassifier_colsample_bytree': 0.42000000000000004, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.02, 'xgbclassifier_lambda': 1.3800000000000001}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:56:38,209]\u001b[0m Trial 275 finished with value: 0.7476563789087532 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.86, 'xgbclassifier_colsample_bytree': 0.43000000000000005, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 0.9600000000000001, 'xgbclassifier_lambda': 1.3}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 23:58:37,041]\u001b[0m Trial 276 finished with value: 0.747280325094685 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.86, 'xgbclassifier_colsample_bytree': 0.43000000000000005, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.2, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 0.9600000000000001, 'xgbclassifier_lambda': 1.3}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-22 00:00:30,190]\u001b[0m Trial 277 finished with value: 0.7473609080548425 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.85, 'xgbclassifier_colsample_bytree': 0.47, 'xgbclassifier_colsample_bylevel': 0.99, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.0, 'xgbclassifier_lambda': 1.26}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 00:02:25,182]\u001b[0m Trial 278 finished with value: 0.7463018177213442 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.83, 'xgbclassifier_colsample_bytree': 0.45000000000000007, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.03, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.02, 'xgbclassifier_lambda': 1.36}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 00:02:30,734]\u001b[0m Trial 279 finished with value: 0.6306422461924551 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.85, 'xgbclassifier_colsample_bytree': 0.42000000000000004, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.03, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 2, 'xgbclassifier_alpha': 0.9, 'xgbclassifier_lambda': 1.3}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 00:04:14,165]\u001b[0m Trial 280 finished with value: 0.7473340470681232 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.82, 'xgbclassifier_colsample_bytree': 0.44000000000000006, 'xgbclassifier_colsample_bylevel': 0.98, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 26, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 0.9600000000000001, 'xgbclassifier_lambda': 1.4000000000000001}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 00:04:33,593]\u001b[0m Trial 281 finished with value: 0.6768277942141435 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.86, 'xgbclassifier_colsample_bytree': 0.42000000000000004, 'xgbclassifier_colsample_bylevel': 0.14, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.2, 'xgbclassifier_eta': 0.04, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.06, 'xgbclassifier_lambda': 1.36}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-22 00:06:16,921]\u001b[0m Trial 282 finished with value: 0.7475412603942426 and parameters: {'scalers': None, 'xgbclassifier_subsample': 0.83, 'xgbclassifier_colsample_bytree': 0.48, 'xgbclassifier_colsample_bylevel': 1.0, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.1, 'xgbclassifier_lambda': 1.46}. Best is trial 259 with value: 0.7479940598846513.\u001b[0m\n",
      "\u001b[33m[W 2023-04-22 00:06:56,479]\u001b[0m Trial 283 failed with parameters: {'scalers': None, 'xgbclassifier_subsample': 0.30000000000000004, 'xgbclassifier_colsample_bytree': 0.45999999999999996, 'xgbclassifier_colsample_bylevel': 0.97, 'xgbclassifier_min_child_weight': 8, 'xgbclassifier_gamma': 0.25, 'xgbclassifier_eta': 0.05, 'xgbclassifier_max_depth': 28, 'xgbclassifier_n_estimators': 275, 'xgbclassifier_max_leaves': 0, 'xgbclassifier_alpha': 1.04, 'xgbclassifier_lambda': 1.46} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_1652\\3133829120.py\", line 70, in objective\n",
      "    score = cross_val_score(pipeline, merged_data.values, train_labels.values.ravel()-1, scoring='f1_micro', cv=3)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 509, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 267, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-04-22 00:06:56,485]\u001b[0m Trial 283 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 76>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m#study = optuna.create_study(direction=\"maximize\") # maximise the score during tuning\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# run the objective function 100 times\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_trial)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     61\u001b[0m estimator \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimators \u001b[38;5;241m=\u001b[39m xgbclassifier_n_estimators, colsample_bylevel \u001b[38;5;241m=\u001b[39m xgbclassifier_colsample_bylevel, \n\u001b[0;32m     62\u001b[0m                                   max_depth \u001b[38;5;241m=\u001b[39m xgbclassifier_max_depth, max_leaves \u001b[38;5;241m=\u001b[39m xgbclassifier_max_leaves, \n\u001b[0;32m     63\u001b[0m                                   eta \u001b[38;5;241m=\u001b[39m xgbclassifier_eta,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, \n\u001b[0;32m     64\u001b[0m                                  subsample \u001b[38;5;241m=\u001b[39m xgbclassifier_subsample, colsample_bytree \u001b[38;5;241m=\u001b[39m xgbclassifier_colsample_bytree,\n\u001b[0;32m     65\u001b[0m                                  min_child_weight \u001b[38;5;241m=\u001b[39m xgbclassifier_min_child_weight, gamma \u001b[38;5;241m=\u001b[39m xgbclassifier_gamma,  \n\u001b[0;32m     66\u001b[0m                                   objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m'\u001b[39m, num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, reg_lambda \u001b[38;5;241m=\u001b[39m xgbclassifier_lambda, reg_alpha \u001b[38;5;241m=\u001b[39m xgbclassifier_alpha)\n\u001b[0;32m     68\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m make_pipeline(scaler, estimator)\n\u001b[1;32m---> 70\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1_micro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m f1 \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;66;03m# calculate the mean of scores\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f1\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    393\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def objective(trial):\n",
    "    \n",
    "    #scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard', 'robust', None])\n",
    "    scalers = trial.suggest_categorical(\"scalers\", [None])\n",
    "    \n",
    "    if scalers == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scalers == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    elif scalers == \"robust\":\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        scaler='passthrough'\n",
    "        \n",
    "#     dim_red = trial.suggest_categorical(\"dim_red\", [\"PCA\", None])\n",
    "    \n",
    "#     if dim_red == \"PCA\":\n",
    "#         pca_n_components=trial.suggest_int(\"pca_n_components\", 20, 65,5) # suggest an integer from 2 to 30\n",
    "#         dimen_red_algorithm=PCA(n_components=pca_n_components, random_state=42)\n",
    "        \n",
    "# #     elif dim_red==\"SelectKBest\":\n",
    "# #         selectkbest_k=trial.suggest_int(\"selectkbest_k\", 20, 65,5) # suggest an integer from 2 to 30\n",
    "# #         dimen_red_algorithm=SelectKBest(f_classif, k=selectkbest_k)\n",
    "        \n",
    "#     else:\n",
    "#         dimen_red_algorithm='passthrough'\n",
    "        \n",
    "    \n",
    "    xgbclassifier_subsample = trial.suggest_float('xgbclassifier_subsample', 0.1,1.0,step=0.01)\n",
    "    xgbclassifier_colsample_bytree = trial.suggest_float('xgbclassifier_colsample_bytree', 0.1,1.0,step=0.01)\n",
    "    xgbclassifier_colsample_bylevel = trial.suggest_float('xgbclassifier_colsample_bylevel', 0.1,1.0,step=0.01)\n",
    "    #xgbclassifier_colsample_bynode = trial.suggest_float('xgbclassifier_colsample_bynode', 0.5,1.0,step=0.1)\n",
    "    xgbclassifier_min_child_weight= trial.suggest_int(\"xgbclassifier_min_child_weight\",2,12,2)\n",
    "    xgbclassifier_gamma = trial.suggest_float('xgbclassifier_gamma', 0.0,0.7,step=0.05)\n",
    "    #xgbclassifier_eta = trial.suggest_float('xgbclassifier_eta', 0.05,0.3,step=0.05)\n",
    "    xgbclassifier_eta = trial.suggest_float('xgbclassifier_eta', 0.01,0.2,step=0.01)\n",
    "    xgbclassifier_max_depth = trial.suggest_int(\"xgbclassifier_max_depth\",4,30,2)\n",
    "    xgbclassifier_n_estimators = trial.suggest_int(\"xgbclassifier_n_estimators\",100,350,25)\n",
    "    xgbclassifier_max_leaves = trial.suggest_int(\"xgbclassifier_max_leaves\",0,14,2)\n",
    "    xgbclassifier_alpha = trial.suggest_float(\"xgbclassifier_alpha\",0.04,2.0,step=0.02)\n",
    "    xgbclassifier_lambda = trial.suggest_float(\"xgbclassifier_lambda\",0.04,2.0,step=0.02)\n",
    "    #xgbclassifier_grow_policy = trial.suggest_categorical(\"xgbclassifier_grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    #xgbclassifier_objective = trial.suggest_categorical(\"xgbclassifier_objective\", [\"multi:softmax\"])\n",
    "    \n",
    "#     if xgbclassifier_objective == \"multi:softprob\":\n",
    "#         xgbclassifier_eval_metric = trial.suggest_categorical(\"xgbclassifier_eval_metric\", [\"logloss\", \"mlogloss\", \"auc\"])\n",
    "        \n",
    "#         estimator = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = xgbclassifier_n_estimators, colsample_bylevel = xgbclassifier_colsample_bylevel, \n",
    "#                                   max_depth = xgbclassifier_max_depth, max_leaves = xgbclassifier_max_leaves, \n",
    "#                                   eta = xgbclassifier_eta,random_state=42, colsample_bynode = xgbclassifier_colsample_bynode,\n",
    "#                                  subsample = xgbclassifier_subsample, colsample_bytree = xgbclassifier_colsample_bytree, eval_metric = xgbclassifier_eval_metric,\n",
    "#                                  min_child_weight = xgbclassifier_min_child_weight, gamma = xgbclassifier_gamma, grow_policy = xgbclassifier_grow_policy,  \n",
    "#                                   objective = xgbclassifier_objective, reg_lambda = xgbclassifier_lambda, reg_alpha = xgbclassifier_alpha)\n",
    "        \n",
    "    #else:\n",
    "    #xgbclassifier_eval_metric = trial.suggest_categorical(\"xgbclassifier_eval_metric\", [\"logloss\", \"mlogloss\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    estimator = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = xgbclassifier_n_estimators, colsample_bylevel = xgbclassifier_colsample_bylevel, \n",
    "                                      max_depth = xgbclassifier_max_depth, max_leaves = xgbclassifier_max_leaves, \n",
    "                                      eta = xgbclassifier_eta,random_state=42, \n",
    "                                     subsample = xgbclassifier_subsample, colsample_bytree = xgbclassifier_colsample_bytree,\n",
    "                                     min_child_weight = xgbclassifier_min_child_weight, gamma = xgbclassifier_gamma,  \n",
    "                                      objective = 'multi:softmax', num_class=3, reg_lambda = xgbclassifier_lambda, reg_alpha = xgbclassifier_alpha)\n",
    "\n",
    "    pipeline = make_pipeline(scaler, estimator)\n",
    "    \n",
    "    score = cross_val_score(pipeline, merged_data.values, train_labels.values.ravel()-1, scoring='f1_micro', cv=3)\n",
    "    \n",
    "    f1 = score.mean() # calculate the mean of scores\n",
    "    return f1\n",
    "\n",
    "#study = optuna.create_study(direction=\"maximize\") # maximise the score during tuning\n",
    "study.optimize(objective, n_trials=50) # run the objective function 100 times\n",
    "\n",
    "print(study.best_trial) # print the best performing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7855222",
   "metadata": {
    "id": "3bc751df"
   },
   "source": [
    "### Randomized GridSearch for CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e1306",
   "metadata": {
    "id": "326e1306"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-21 08:25:36,958]\u001b[0m A new study created in memory with name: no-name-044ab4e4-4ae2-4770-9d0b-dbcec10138a7\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 08:25:49,187]\u001b[0m Trial 0 finished with value: 0.7361445274576844 and parameters: {'depth': 6, 'iterations': 100, 'learning_rate': 0.3, 'l2_leaf_reg': 3, 'border_count': 11, 'grow_policy': 'SymmetricTree'}. Best is trial 0 with value: 0.7361445274576844.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 08:26:22,915]\u001b[0m Trial 1 finished with value: 0.7408797356878907 and parameters: {'depth': 8, 'iterations': 500, 'learning_rate': 0.15, 'l2_leaf_reg': 7, 'border_count': 17, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.7408797356878907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 08:26:50,507]\u001b[0m Trial 2 finished with value: 0.7296518432392815 and parameters: {'depth': 2, 'iterations': 1000, 'learning_rate': 0.05, 'l2_leaf_reg': 17, 'border_count': 13, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: 0.7408797356878907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 08:35:03,176]\u001b[0m Trial 3 finished with value: 0.7306418624640735 and parameters: {'depth': 14, 'iterations': 500, 'learning_rate': 0.01, 'l2_leaf_reg': 15, 'border_count': 17, 'grow_policy': 'SymmetricTree'}. Best is trial 1 with value: 0.7408797356878907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-21 08:35:15,057]\u001b[0m Trial 4 finished with value: 0.7309641943047033 and parameters: {'depth': 10, 'iterations': 10, 'learning_rate': 0.03, 'l2_leaf_reg': 1, 'border_count': 15, 'grow_policy': 'Depthwise'}. Best is trial 1 with value: 0.7408797356878907.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "        \n",
    "    \n",
    "    depth = trial.suggest_int('depth', 2,20)\n",
    "    iterations = trial.suggest_int('iterations', 10,5000)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001,0.3,step=0.001)\n",
    "    l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1,19)\n",
    "    border_count = trial.suggest_int('border_count', 10,20)\n",
    "    grow_policy = trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide'])\n",
    "    #max_leaves = trial.suggest_int('max_leaves', 2,31)\n",
    "    #eval_metric = trial.suggest_categorical('eval_metrics', ['TotalF1'])\n",
    "    #xgbclassifier_colsample_bynode = trial.suggest_float('xgbclassifier_colsample_bynode', 0.5,1.0,step=0.1)\n",
    "\n",
    "    estimator = CatBoostClassifier(eval_metric= 'TotalF1', task_type=\"GPU\", grow_policy = grow_policy, cat_features=cat_cols, depth = depth, iterations = iterations,\n",
    "                                  learning_rate = learning_rate, l2_leaf_reg = l2_leaf_reg, border_count = border_count, verbose = 0)\n",
    "\n",
    "    #pipeline = make_pipeline(scaler,dimen_red_algorithm, estimator)\n",
    "    \n",
    "    score = cross_val_score(estimator, train_values, train_labels, scoring='f1_micro', cv=3)\n",
    "    \n",
    "    f1 = score.mean() # calculate the mean of scores\n",
    "    return f1\n",
    "\n",
    "search_space = {'depth':[2,4,6,8,10,12,14,16],\n",
    "            'iterations':[10,100,500,1000,5000],\n",
    "            'learning_rate':[0.001,0.01,0.02,0.03,0.04,0.05,0.06,0.07, 0.09,0.1, 0.15, 0.2, 0.3], \n",
    "            'l2_leaf_reg':[1,3,5,7,9,11,13, 15,17],\n",
    "            'border_count':[11,13,15,17, 17],\n",
    "            'grow_policy': ['SymmetricTree', 'Depthwise'],\n",
    "            #'max_leaves': [2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,31]\n",
    "            #'eval_metrics': ['TotalF1']\n",
    "               }\n",
    "\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler=sampler) # maximise the score during tuning\n",
    "\n",
    "study.optimize(objective, n_trials=150) # run the objective function 100 times\n",
    "\n",
    "print(study.best_trial) # print the best performing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X_Hx_K8Xzrz-",
   "metadata": {
    "id": "X_Hx_K8Xzrz-"
   },
   "source": [
    "## MLXTEND"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d091c",
   "metadata": {},
   "source": [
    "### Ignore anything related to scaling below because it is not used in the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d29bc0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 't'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:416\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:453\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m     )\n\u001b[0;32m    452\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 453\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    462\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 't'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(merged_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2492845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vLW5vY1i0HJN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLW5vY1i0HJN",
    "outputId": "dd71ee73-9f39-4839-b0e7-81f962a83dd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_data.columns[~merged_data.columns.isin(selected_features)].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3664d359",
   "metadata": {
    "id": "3664d359"
   },
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import Pipeline\n",
    "\n",
    "############### Only need clf1,2 and 3 from here ##################\n",
    "\n",
    "\n",
    "\n",
    "#col_sel1 = ColumnSelector(cols=merged_data.columns[0:38].values)\n",
    "#col_sel2 = ColumnSelector(cols=merged_data.columns[~merged_data.columns.isin(selected_features)].values)\n",
    "\n",
    "clf1 = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = 325, \n",
    "                                  max_depth = 24, max_leaves = 0, \n",
    "                                  eta = 0.060000000000000005,random_state=42,\n",
    "                                  subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "                                  min_child_weight = 12, gamma = 0.5, \n",
    "                                  objective = \"multi:softmax\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf2 = lgb.LGBMClassifier(n_estimators = 325, \n",
    "                                  max_depth = 24, num_leaves = 131072, \n",
    "                                  learning_rate = 0.060000000000000005,random_state=42,\n",
    "                                  subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "                                  min_child_weight = 12, min_gain_to_split = 0.4,\n",
    "                                  objective = \"multiclass\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "# clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 8, iterations = 5000,\n",
    "#                                    learning_rate = 0.05, l2_leaf_reg = 7, border_count = 11, verbose = 0)\n",
    "\n",
    "# clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 16, iterations = 500, random_state = 42,\n",
    "#                                    learning_rate = 0.07, l2_leaf_reg = 3, border_count = 17, grow_policy = 'Depthwise', verbose = 0)\n",
    "\n",
    "# clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 12, iterations = 1000, random_state = 42,\n",
    "#                                     learning_rate = 0.03, l2_leaf_reg = 5, border_count = 11, grow_policy = 'Depthwise', verbose = 0)\n",
    "\n",
    "clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 12, iterations = 500, random_state = 42,\n",
    "                                    learning_rate = 0.07, l2_leaf_reg = 15, border_count = 17, grow_policy = 'Depthwise', verbose = 0)\n",
    "                          \n",
    "#clf1_pipe = Pipeline([('sel', col_sel2),\n",
    "#                      ('logreg', clf1)])\n",
    "\n",
    "# clf2_pipe = Pipeline([('sel', col_sel2),\n",
    "#                       ('logreg', clf2)])\n",
    "\n",
    "# clf3_pipe = Pipeline([('sel', col_sel1),\n",
    "#                       ('logreg', clf3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ed9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### NEW TEST ##############################\n",
    "\n",
    "# clf1 = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = 300, \n",
    "#                                   max_depth = 24, max_leaves = 0, \n",
    "#                                   eta = 0.060000000000000005,random_state=42,\n",
    "#                                   subsample = 0.92, colsample_bytree = 0.36, colsample_bylevel = 1.0,\n",
    "#                                   min_child_weight = 10, gamma = 0.30000000000000004, \n",
    "#                                   objective = \"multi:softmax\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 1.34)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clf2 = lgb.LGBMClassifier(n_estimators = 300, device=\"gpu\",\n",
    "#                                   max_depth = 24, num_leaves = 131072, \n",
    "#                                   learning_rate = 0.060000000000000005,random_state=42,\n",
    "#                                   subsample = 0.92, colsample_bytree = 0.36, colsample_bylevel = 1.0,\n",
    "#                                   min_child_weight = 10, min_gain_to_split = 0.30000000000000004,\n",
    "#                                   objective = \"multiclass\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 1.34)\n",
    "\n",
    "clf1 = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = 325, \n",
    "                                  max_depth = 24, max_leaves = 0, \n",
    "                                  eta = 0.060000000000000005,random_state=42,\n",
    "                                  subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "                                  min_child_weight = 12, gamma = 0.5, \n",
    "                                  objective = \"multi:softmax\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf2 = lgb.LGBMClassifier(n_estimators = 325, \n",
    "                                  max_depth = 24, num_leaves = 131072, \n",
    "                                  learning_rate = 0.060000000000000005,random_state=42,\n",
    "                                  subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "                                  min_child_weight = 12, min_gain_to_split = 0.4,\n",
    "                                  objective = \"multiclass\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "\n",
    "# clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 8, iterations = 5000,\n",
    "#                                    learning_rate = 0.05, l2_leaf_reg = 7, border_count = 11, verbose = 0)\n",
    "\n",
    "clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 16, iterations = 500, random_state = 42,\n",
    "                                   learning_rate = 0.07, l2_leaf_reg = 3, border_count = 17, grow_policy = 'Depthwise', verbose = 0)\n",
    "\n",
    "# clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 12, iterations = 1000, random_state = 42,\n",
    "#                                     learning_rate = 0.03, l2_leaf_reg = 5, border_count = 11, grow_policy = 'Depthwise', verbose = 0)\n",
    "\n",
    "# clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 12, iterations = 500, random_state = 42,\n",
    "#                                     learning_rate = 0.07, l2_leaf_reg = 15, border_count = 17, grow_policy = 'Depthwise', verbose = 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wT-jEndn3BeT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "wT-jEndn3BeT",
    "outputId": "4f246998-ff03-4461-8c56-137d854176c2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0f4f283a2c20>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "(y_train.values.ravel()-1).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "G5f3eKB02ekx",
   "metadata": {
    "id": "G5f3eKB02ekx"
   },
   "outputs": [],
   "source": [
    "#### SPlitting Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_data, train_labels, test_size=0.2, shuffle = True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b51403",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "WsCKPmvTBvfh",
    "outputId": "bd9988eb-651c-442a-a408-e2586100c5e8"
   },
   "source": [
    "#### Ignore anything using mlxtend below because I could not figure out how to pass different dataframes to catboost and the other two without using sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4w8E1wek14nb",
   "metadata": {
    "id": "4w8E1wek14nb"
   },
   "outputs": [],
   "source": [
    "#eclf = EnsembleVoteClassifier(clfs=[clf1_pipe, clf2_pipe, clf3_pipe], \n",
    "#                             voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y4sOfdPZ2oXP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "y4sOfdPZ2oXP",
    "outputId": "d72600dc-5cf3-4668-b650-28d3164178b4"
   },
   "outputs": [],
   "source": [
    "#eclf.fit(X_train,y_train.values.ravel()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ZaSWKiIK_6C7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaSWKiIK_6C7",
    "outputId": "3c52b31a-97b7-4d40-bfcc-1b41512c61ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 257, 8352, ..., 0, 0, 0],\n",
       "       [6, 1076, 9202, ..., 0, 0, 0],\n",
       "       [7, 838, 10723, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [8, 1073, 5249, ..., 0, 0, 0],\n",
       "       [10, 76, 1841, ..., 0, 0, 0],\n",
       "       [7, 746, 10603, ..., 0, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test = col_sel1.transform(X_train)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "zTLp5kfXEYBC",
   "metadata": {
    "id": "zTLp5kfXEYBC"
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import VotingClassifier\n",
    "#merged_data.drop(selected_features, axis='columns', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1e545",
   "metadata": {},
   "source": [
    "#### Making the train and test splits to be passed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5JfpIq9nFuLC",
   "metadata": {
    "id": "5JfpIq9nFuLC"
   },
   "outputs": [],
   "source": [
    "X_train_cat = X_train[train_values.columns.values]\n",
    "X_train_other = X_train.drop(selected_features, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lPGFXxv6LpbY",
   "metadata": {
    "id": "lPGFXxv6LpbY"
   },
   "outputs": [],
   "source": [
    "X_test_cat = X_test[train_values.columns.values]\n",
    "X_test_other = X_test.drop(selected_features, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "uOZarH3vHlk-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "uOZarH3vHlk-",
    "outputId": "056ca8cf-a108-4132-d7bb-ea09a9d1fe47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739427</th>\n",
       "      <td>13</td>\n",
       "      <td>257</td>\n",
       "      <td>8352</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17201</th>\n",
       "      <td>6</td>\n",
       "      <td>1076</td>\n",
       "      <td>9202</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723805</th>\n",
       "      <td>7</td>\n",
       "      <td>838</td>\n",
       "      <td>10723</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891512</th>\n",
       "      <td>7</td>\n",
       "      <td>555</td>\n",
       "      <td>2763</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484350</th>\n",
       "      <td>17</td>\n",
       "      <td>682</td>\n",
       "      <td>1039</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79888</th>\n",
       "      <td>13</td>\n",
       "      <td>909</td>\n",
       "      <td>1626</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442764</th>\n",
       "      <td>10</td>\n",
       "      <td>1397</td>\n",
       "      <td>8182</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17256</th>\n",
       "      <td>8</td>\n",
       "      <td>1073</td>\n",
       "      <td>5249</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496181</th>\n",
       "      <td>10</td>\n",
       "      <td>76</td>\n",
       "      <td>1841</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246461</th>\n",
       "      <td>7</td>\n",
       "      <td>746</td>\n",
       "      <td>10603</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208480 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "building_id                                                   \n",
       "739427                   13             257            8352   \n",
       "17201                     6            1076            9202   \n",
       "723805                    7             838           10723   \n",
       "891512                    7             555            2763   \n",
       "484350                   17             682            1039   \n",
       "...                     ...             ...             ...   \n",
       "79888                    13             909            1626   \n",
       "442764                   10            1397            8182   \n",
       "17256                     8            1073            5249   \n",
       "496181                   10              76            1841   \n",
       "246461                    7             746           10603   \n",
       "\n",
       "             count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "building_id                                                                 \n",
       "739427                         3   25                2                  5   \n",
       "17201                          3   40               10                  8   \n",
       "723805                         2   45                8                  5   \n",
       "891512                         2   30                7                  4   \n",
       "484350                         3   30                6                  7   \n",
       "...                          ...  ...              ...                ...   \n",
       "79888                          2   25                6                  5   \n",
       "442764                         2    5                5                  4   \n",
       "17256                          3   20               22                  7   \n",
       "496181                         3   10               11                  7   \n",
       "246461                         2    0                7                  5   \n",
       "\n",
       "            land_surface_condition foundation_type roof_type  ...  \\\n",
       "building_id                                                   ...   \n",
       "739427                           n               r         n  ...   \n",
       "17201                            o               r         n  ...   \n",
       "723805                           t               r         n  ...   \n",
       "891512                           t               r         n  ...   \n",
       "484350                           t               r         q  ...   \n",
       "...                            ...             ...       ...  ...   \n",
       "79888                            t               r         q  ...   \n",
       "442764                           n               r         n  ...   \n",
       "17256                            o               r         q  ...   \n",
       "496181                           t               r         q  ...   \n",
       "246461                           t               r         n  ...   \n",
       "\n",
       "            has_secondary_use_agriculture has_secondary_use_hotel  \\\n",
       "building_id                                                         \n",
       "739427                                  0                       0   \n",
       "17201                                   0                       0   \n",
       "723805                                  0                       0   \n",
       "891512                                  0                       0   \n",
       "484350                                  0                       0   \n",
       "...                                   ...                     ...   \n",
       "79888                                   0                       0   \n",
       "442764                                  0                       0   \n",
       "17256                                   0                       1   \n",
       "496181                                  0                       0   \n",
       "246461                                  0                       0   \n",
       "\n",
       "            has_secondary_use_rental has_secondary_use_institution  \\\n",
       "building_id                                                          \n",
       "739427                             0                             0   \n",
       "17201                              1                             0   \n",
       "723805                             0                             0   \n",
       "891512                             0                             0   \n",
       "484350                             0                             0   \n",
       "...                              ...                           ...   \n",
       "79888                              0                             0   \n",
       "442764                             0                             0   \n",
       "17256                              0                             0   \n",
       "496181                             0                             0   \n",
       "246461                             0                             0   \n",
       "\n",
       "             has_secondary_use_school  has_secondary_use_industry  \\\n",
       "building_id                                                         \n",
       "739427                              0                           0   \n",
       "17201                               0                           0   \n",
       "723805                              0                           0   \n",
       "891512                              0                           0   \n",
       "484350                              0                           0   \n",
       "...                               ...                         ...   \n",
       "79888                               0                           0   \n",
       "442764                              0                           0   \n",
       "17256                               0                           0   \n",
       "496181                              0                           0   \n",
       "246461                              0                           0   \n",
       "\n",
       "             has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "building_id                                                                \n",
       "739427                                   0                             0   \n",
       "17201                                    0                             0   \n",
       "723805                                   0                             0   \n",
       "891512                                   0                             0   \n",
       "484350                                   0                             0   \n",
       "...                                    ...                           ...   \n",
       "79888                                    0                             0   \n",
       "442764                                   0                             0   \n",
       "17256                                    0                             0   \n",
       "496181                                   0                             0   \n",
       "246461                                   0                             0   \n",
       "\n",
       "             has_secondary_use_use_police  has_secondary_use_other  \n",
       "building_id                                                         \n",
       "739427                                  0                        0  \n",
       "17201                                   0                        0  \n",
       "723805                                  0                        0  \n",
       "891512                                  0                        0  \n",
       "484350                                  0                        0  \n",
       "...                                   ...                      ...  \n",
       "79888                                   0                        0  \n",
       "442764                                  0                        0  \n",
       "17256                                   0                        0  \n",
       "496181                                  0                        0  \n",
       "246461                                  0                        0  \n",
       "\n",
       "[208480 rows x 38 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5Lj5XRjEFvbE",
   "metadata": {
    "id": "5Lj5XRjEFvbE"
   },
   "outputs": [],
   "source": [
    "# eclf = VotingClassifier(\n",
    "#      estimators=[('xgb', clf1), ('lgbm', clf2), ('cat', clf3)],\n",
    "#     voting='soft')\n",
    "\n",
    "##################### Final Classifier List clf1,2,3 from above ##############################\n",
    "\n",
    "classifiers = [('xgb', clf1), ('lgbm', clf2), ('cat', clf3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f82d0",
   "metadata": {},
   "source": [
    "### As mentioned above could not figure out how to pass seperate datas for mlxtend so found this wonderful manual implementation of sklearn's ensemble classifier with the modification of multiple data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nHhquBCUHqIO",
   "metadata": {
    "id": "nHhquBCUHqIO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fit_multiple_estimators(classifiers, X_list, y, sample_weights = None):\n",
    "\n",
    "    # Convert the labels `y` using LabelEncoder, because the predict method is using index-based pointers\n",
    "    # which will be converted back to original data later.\n",
    "    le_ = LabelEncoder()\n",
    "    le_.fit(y)\n",
    "    transformed_y = le_.transform(y)\n",
    "\n",
    "    # Fit all estimators with their respective feature arrays\n",
    "    estimators_ = [clf.fit(X, y) if sample_weights is None else clf.fit(X, y, sample_weights) for clf, X in zip([clf for _, clf in classifiers], X_list)]\n",
    "\n",
    "    return estimators_, le_\n",
    "\n",
    "\n",
    "def predict_from_multiple_estimator(estimators, label_encoder, X_list, weights = None):\n",
    "\n",
    "    # Predict 'soft' voting with probabilities\n",
    "\n",
    "    pred1 = np.asarray([clf.predict_proba(X) for clf, X in zip(estimators, X_list)])\n",
    "    pred2 = np.average(pred1, axis=0, weights=weights)\n",
    "    pred = np.argmax(pred2, axis=1)\n",
    "\n",
    "    # Convert integer predictions to original labels:\n",
    "    return label_encoder.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c779182",
   "metadata": {},
   "source": [
    "#### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "lq3jq406JIE9",
   "metadata": {
    "id": "lq3jq406JIE9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.30000000000000004, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train_list = [X_train_other, X_train_other, X_train_cat]\n",
    "fitted_estimators, label_encoder = fit_multiple_estimators(classifiers, X_train_list, y_train.values.ravel()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9vQPHBeIL6Ux",
   "metadata": {
    "id": "9vQPHBeIL6Ux"
   },
   "outputs": [],
   "source": [
    "X_test_list = [X_test_other, X_test_other, X_test_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9nqfNdXxJgIv",
   "metadata": {
    "id": "9nqfNdXxJgIv"
   },
   "outputs": [],
   "source": [
    "#1.06682501, 0.8434502 , 1.04286667 1.1609375 , 0.93671875, 1.0\n",
    "#y_pred = predict_from_multiple_estimator(fitted_estimators, label_encoder, X_test_list, [1.06682501, 0.8434502 , 1.04286667])\n",
    "#1.01601562, 1.04140625, 1.0\n",
    "y_pred = predict_from_multiple_estimator(fitted_estimators, label_encoder, X_test_list, [0.95991211, 0.99814453, 1.0])\n",
    "#0.99916992, 1.0019043, 1.0\n",
    "#y_pred = predict_from_multiple_estimator(fitted_estimators, label_encoder, X_test_list, [0.99916992, 1.0019043, 1.0])\n",
    "#1.065625 , 0.9640625, 1.0\n",
    "#1.009375, 1.046875, 1.0\n",
    "#y_pred = predict_from_multiple_estimator(fitted_estimators, label_encoder, X_test_list, [1.009375, 1.046875, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "NjHQS8qkMkow",
   "metadata": {
    "id": "NjHQS8qkMkow"
   },
   "outputs": [],
   "source": [
    "#train_pred = predict_from_multiple_estimator(fitted_estimators, label_encoder, X_train_list, [1.06682501, 0.8434502 , 1.04286667])\n",
    "train_pred = predict_from_multiple_estimator(fitted_estimators, label_encoder, X_train_list, [0.95991211, 0.99814453, 1.0])\n",
    "#train_pred = predict_from_multiple_estimator(fitted_estimators, label_encoder, X_train_list, [1.06682501, 0.8434502 , 1.04286667])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8CBQkzx3MB9V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8CBQkzx3MB9V",
    "outputId": "9dbb7ff5-f6bd-4ba1-9455-28a848fddee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7498129352852018\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test.values.ravel(), y_pred +1, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "lc26lpwKMZww",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lc26lpwKMZww",
    "outputId": "b0727371-f74c-4aaf-d9da-a0915d339e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8285542977743667\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train.values.ravel(), train_pred +1, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1e36f",
   "metadata": {},
   "source": [
    "### Finding optimal weight splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "728d21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Class to use for optimization ##########\n",
    "\n",
    "class TestEnsemble:\n",
    "    def __init__(self, weights, estimator = None, label_encoder = None):\n",
    "        self.weights = weights\n",
    "#         self.clf1 = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = 325, \n",
    "#                                   max_depth = 24, max_leaves = 0, \n",
    "#                                   eta = 0.060000000000000005,random_state=42,\n",
    "#                                   subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "#                                   min_child_weight = 12, gamma = 0.5, \n",
    "#                                   objective = \"multi:softmax\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         self.clf2 = lgb.LGBMClassifier(n_estimators = 325, \n",
    "#                                           max_depth = 24, num_leaves = 131072, \n",
    "#                                           learning_rate = 0.060000000000000005,random_state=42,\n",
    "#                                           subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "#                                           min_child_weight = 12, min_gain_to_split = 0.4,\n",
    "#                                           objective = \"multiclass\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "        self.clf1 = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = 325, \n",
    "                                          max_depth = 24, max_leaves = 0, \n",
    "                                          eta = 0.060000000000000005,random_state=42,\n",
    "                                          subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "                                          min_child_weight = 12, gamma = 0.5, \n",
    "                                          objective = \"multi:softmax\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.clf2 = lgb.LGBMClassifier(n_estimators = 325, \n",
    "                                          max_depth = 24, num_leaves = 131072, \n",
    "                                          learning_rate = 0.060000000000000005,random_state=42,\n",
    "                                          subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "                                          min_child_weight = 12, min_gain_to_split = 0.4,\n",
    "                                          objective = \"multiclass\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "        self.clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 8, iterations = 5000,\n",
    "                                           learning_rate = 0.05, l2_leaf_reg = 7, border_count = 11, verbose = 0)\n",
    "\n",
    "        self.classifiers = [('xgb', self.clf1), ('lgbm', self.clf2), ('cat', self.clf3)]\n",
    "        self.estimators = estimator\n",
    "        self.label_encoder = label_encoder\n",
    "        \n",
    "    def fit_multiple_estimators(self,classifiers, X_list, y, sample_weights = None):\n",
    "\n",
    "        # Convert the labels `y` using LabelEncoder, because the predict method is using index-based pointers\n",
    "        # which will be converted back to original data later.\n",
    "        le_ = LabelEncoder()\n",
    "        le_.fit(y)\n",
    "        transformed_y = le_.transform(y)\n",
    "\n",
    "        # Fit all estimators with their respective feature arrays\n",
    "        estimators_ = [clf.fit(X, y) if sample_weights is None else clf.fit(X, y, sample_weights) for clf, X in zip([clf for _, clf in classifiers], X_list)]\n",
    "\n",
    "        return estimators_, le_\n",
    "\n",
    "\n",
    "    def predict_from_multiple_estimator(self,estimators, label_encoder, X_list, weights = None):\n",
    "\n",
    "        # Predict 'soft' voting with probabilities\n",
    "\n",
    "        pred1 = np.asarray([clf.predict_proba(X) for clf, X in zip(estimators, X_list)])\n",
    "        pred2 = np.average(pred1, axis=0, weights=weights)\n",
    "        pred = np.argmax(pred2, axis=1)\n",
    "\n",
    "        # Convert integer predictions to original labels:\n",
    "        return label_encoder.inverse_transform(pred)\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        self.estimators, self.label_encoder = fit_multiple_estimators(self.classifiers, X, y, sample_weights = None)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        predictions = self.predict_from_multiple_estimator(self.estimators, self.label_encoder, X, self.weights)\n",
    "        return predictions\n",
    "        \n",
    "    def score(self,X,y):\n",
    "        predictions = self.predict(X)\n",
    "        return f1_score(y.values.ravel(), predictions +1, average='micro')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e797679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def function_to_minimize(weights):\n",
    "\n",
    "    w1, w2 = weights  # these are the new weights!\n",
    "\n",
    "    #Use Classifier fitted on split data not total\n",
    "    newclf = TestEnsemble([w1,w2,1.0], fitted_estimators,label_encoder)\n",
    "\n",
    "#     newclf.fit(new_data, train_labels.values.ravel()-1)\n",
    "#     score = newclf.score(new_data, train_labels.values.ravel()-1)\n",
    "    #score = cross_val_score(newclf, new_data, train_labels.values.ravel()-1, scoring='f1_micro').mean()\n",
    "    \n",
    "    #newclf.fit(X_train_list, y_train.values.ravel()-1)\n",
    "    score = newclf.score(X_test_list, y_test)\n",
    "    \n",
    "    # change accuracy to error so that smaller is better\n",
    "    score_to_minimize = 1 - score\n",
    "\n",
    "    return score_to_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e636d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = [1., 1.]\n",
    "\n",
    "results = minimize(\n",
    "    function_to_minimize,\n",
    "    init_weights,\n",
    "    bounds=((0, 5), (0, 5)),\n",
    "    method=\"nelder-mead\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50e7464e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[1.009375  , 1.046875  ],\n",
       "       [1.00936279, 1.04681396],\n",
       "       [1.00943909, 1.04680481]]), array([0.25018706, 0.25018706, 0.25018706]))\n",
       "           fun: 0.25018706471479824\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 48\n",
       "           nit: 17\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([1.009375, 1.046875])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### use value of \"x\"\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d26057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## dropping redundant columns for xgboost and lgbm ############\n",
    "\n",
    "final_other = merged_data.drop(selected_features, axis='columns')\n",
    "# scaler1 = MinMaxScaler()\n",
    "# scaler2 = MinMaxScaler()\n",
    "\n",
    "# cat_data_cols = train_values.columns[~train_values.columns.isin(selected_features + ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'])].values\n",
    "# other_data_cols = final_other.columns[~final_other.columns.isin(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'])]\n",
    "# train_values.loc[:, cat_data_cols] = scaler1.fit_transform(train_values[cat_data_cols])\n",
    "# final_other.loc[:, other_data_cols] = scaler2.fit_transform(final_other[other_data_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9bf88",
   "metadata": {},
   "source": [
    "### Final model traininig and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "p4e8CpdjMiPf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4e8CpdjMiPf",
    "outputId": "4ace337a-f1be-4435-abdc-636cc3102bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.4, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.4\n"
     ]
    }
   ],
   "source": [
    "# clf1 = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = 300, \n",
    "#                                   max_depth = 24, max_leaves = 0, \n",
    "#                                   eta = 0.060000000000000005,random_state=42,\n",
    "#                                   subsample = 0.92, colsample_bytree = 0.36, colsample_bylevel = 1.0,\n",
    "#                                   min_child_weight = 10, gamma = 0.30000000000000004, \n",
    "#                                   objective = \"multi:softmax\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 1.34)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clf2 = lgb.LGBMClassifier(n_estimators = 300, device=\"gpu\",\n",
    "#                                   max_depth = 24, num_leaves = 131072, \n",
    "#                                   learning_rate = 0.060000000000000005,random_state=42,\n",
    "#                                   subsample = 0.92, colsample_bytree = 0.36, colsample_bylevel = 1.0,\n",
    "#                                   min_child_weight = 10, min_gain_to_split = 0.30000000000000004,\n",
    "#                                   objective = \"multiclass\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 1.34)\n",
    "\n",
    "\n",
    "clf1 = xgb.XGBClassifier(tree_method='gpu_hist', n_estimators = 325, \n",
    "                                  max_depth = 24, max_leaves = 0, \n",
    "                                  eta = 0.060000000000000005,random_state=42,\n",
    "                                  subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "                                  min_child_weight = 12, gamma = 0.5, \n",
    "                                  objective = \"multi:softmax\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf2 = lgb.LGBMClassifier(n_estimators = 325, \n",
    "                                  max_depth = 24, num_leaves = 131072, \n",
    "                                  learning_rate = 0.060000000000000005,random_state=42,\n",
    "                                  subsample = 0.8, colsample_bytree = 0.5, colsample_bylevel = 1.0,\n",
    "                                  min_child_weight = 12, min_gain_to_split = 0.4,\n",
    "                                  objective = \"multiclass\", num_class=3, reg_lambda = 1.4200000000000002, reg_alpha = 0.7000000000000001)\n",
    "\n",
    "\n",
    "# clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 8, iterations = 5000,\n",
    "#                                    learning_rate = 0.05, l2_leaf_reg = 7, border_count = 11, verbose = 0)\n",
    "\n",
    "clf3 = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols, depth = 16, iterations = 500, random_state = 42,\n",
    "                                   learning_rate = 0.07, l2_leaf_reg = 3, border_count = 17, grow_policy = 'Depthwise', verbose = 0)\n",
    "\n",
    "classifiers = [('xgb', clf1), ('lgbm', clf2), ('cat', clf3)]\n",
    "\n",
    "fitted_estimators, label_encoder = fit_multiple_estimators(classifiers, [final_other, final_other, train_values], train_labels.values.ravel()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0b72ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ig-LVC2BNWpw",
   "metadata": {
    "id": "ig-LVC2BNWpw"
   },
   "outputs": [],
   "source": [
    "test_values_subset = test_values[selected_features]\n",
    "test_values_subset = pd.get_dummies(test_values_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "114737bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_test = pd.concat([test_values, test_values_subset], axis='columns')\n",
    "merged_data_test.drop(selected_features, axis='columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28be9c83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#merged_data_test.drop(selected_features, axis='columns', inplace = True)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m merged_data_test\u001b[38;5;241m.\u001b[39mloc[:, other_data_cols] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler2\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(merged_data_test[other_data_cols])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler2' is not defined"
     ]
    }
   ],
   "source": [
    "#merged_data_test.drop(selected_features, axis='columns', inplace = True)\n",
    "merged_data_test.loc[:, other_data_cols] = scaler2.transform(merged_data_test[other_data_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a83b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>plan_configuration_m</th>\n",
       "      <th>plan_configuration_n</th>\n",
       "      <th>plan_configuration_o</th>\n",
       "      <th>plan_configuration_q</th>\n",
       "      <th>plan_configuration_s</th>\n",
       "      <th>plan_configuration_u</th>\n",
       "      <th>legal_ownership_status_a</th>\n",
       "      <th>legal_ownership_status_r</th>\n",
       "      <th>legal_ownership_status_v</th>\n",
       "      <th>legal_ownership_status_w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300051</th>\n",
       "      <td>17</td>\n",
       "      <td>596</td>\n",
       "      <td>11307</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99355</th>\n",
       "      <td>6</td>\n",
       "      <td>141</td>\n",
       "      <td>11987</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890251</th>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10044</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745817</th>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>633</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421793</th>\n",
       "      <td>17</td>\n",
       "      <td>289</td>\n",
       "      <td>7970</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310028</th>\n",
       "      <td>4</td>\n",
       "      <td>605</td>\n",
       "      <td>3623</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663567</th>\n",
       "      <td>10</td>\n",
       "      <td>1407</td>\n",
       "      <td>11907</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049160</th>\n",
       "      <td>22</td>\n",
       "      <td>1136</td>\n",
       "      <td>7712</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442785</th>\n",
       "      <td>6</td>\n",
       "      <td>1041</td>\n",
       "      <td>912</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501372</th>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>6436</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86868 rows  68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "building_id                                                   \n",
       "300051                   17             596           11307   \n",
       "99355                     6             141           11987   \n",
       "890251                   22              19           10044   \n",
       "745817                   26              39             633   \n",
       "421793                   17             289            7970   \n",
       "...                     ...             ...             ...   \n",
       "310028                    4             605            3623   \n",
       "663567                   10            1407           11907   \n",
       "1049160                  22            1136            7712   \n",
       "442785                    6            1041             912   \n",
       "501372                   26              36            6436   \n",
       "\n",
       "             count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "building_id                                                                 \n",
       "300051                         3   20                7                  6   \n",
       "99355                          2   25               13                  5   \n",
       "890251                         2    5                4                  5   \n",
       "745817                         1    0               19                  3   \n",
       "421793                         3   15                8                  7   \n",
       "...                          ...  ...              ...                ...   \n",
       "310028                         3   70               20                  6   \n",
       "663567                         3   25                6                  7   \n",
       "1049160                        1   50                3                  3   \n",
       "442785                         2    5                9                  5   \n",
       "501372                         2   10               11                  4   \n",
       "\n",
       "             has_superstructure_adobe_mud  \\\n",
       "building_id                                 \n",
       "300051                                  0   \n",
       "99355                                   0   \n",
       "890251                                  0   \n",
       "745817                                  0   \n",
       "421793                                  0   \n",
       "...                                   ...   \n",
       "310028                                  0   \n",
       "663567                                  1   \n",
       "1049160                                 0   \n",
       "442785                                  1   \n",
       "501372                                  0   \n",
       "\n",
       "             has_superstructure_mud_mortar_stone  \\\n",
       "building_id                                        \n",
       "300051                                         1   \n",
       "99355                                          1   \n",
       "890251                                         1   \n",
       "745817                                         0   \n",
       "421793                                         1   \n",
       "...                                          ...   \n",
       "310028                                         1   \n",
       "663567                                         1   \n",
       "1049160                                        1   \n",
       "442785                                         1   \n",
       "501372                                         0   \n",
       "\n",
       "             has_superstructure_stone_flag  ...  plan_configuration_m  \\\n",
       "building_id                                 ...                         \n",
       "300051                                   0  ...                     0   \n",
       "99355                                    0  ...                     0   \n",
       "890251                                   0  ...                     0   \n",
       "745817                                   0  ...                     0   \n",
       "421793                                   0  ...                     0   \n",
       "...                                    ...  ...                   ...   \n",
       "310028                                   0  ...                     0   \n",
       "663567                                   1  ...                     0   \n",
       "1049160                                  0  ...                     0   \n",
       "442785                                   0  ...                     0   \n",
       "501372                                   0  ...                     0   \n",
       "\n",
       "             plan_configuration_n  plan_configuration_o  plan_configuration_q  \\\n",
       "building_id                                                                     \n",
       "300051                          0                     0                     0   \n",
       "99355                           0                     0                     0   \n",
       "890251                          0                     0                     0   \n",
       "745817                          0                     0                     0   \n",
       "421793                          0                     0                     0   \n",
       "...                           ...                   ...                   ...   \n",
       "310028                          0                     0                     0   \n",
       "663567                          0                     0                     0   \n",
       "1049160                         0                     0                     0   \n",
       "442785                          0                     0                     0   \n",
       "501372                          0                     0                     0   \n",
       "\n",
       "             plan_configuration_s  plan_configuration_u  \\\n",
       "building_id                                               \n",
       "300051                          0                     0   \n",
       "99355                           0                     0   \n",
       "890251                          0                     0   \n",
       "745817                          0                     0   \n",
       "421793                          0                     0   \n",
       "...                           ...                   ...   \n",
       "310028                          0                     0   \n",
       "663567                          0                     0   \n",
       "1049160                         0                     0   \n",
       "442785                          0                     0   \n",
       "501372                          0                     0   \n",
       "\n",
       "             legal_ownership_status_a  legal_ownership_status_r  \\\n",
       "building_id                                                       \n",
       "300051                              0                         0   \n",
       "99355                               0                         0   \n",
       "890251                              0                         0   \n",
       "745817                              0                         0   \n",
       "421793                              0                         0   \n",
       "...                               ...                       ...   \n",
       "310028                              0                         0   \n",
       "663567                              0                         0   \n",
       "1049160                             0                         0   \n",
       "442785                              1                         0   \n",
       "501372                              0                         0   \n",
       "\n",
       "             legal_ownership_status_v  legal_ownership_status_w  \n",
       "building_id                                                      \n",
       "300051                              1                         0  \n",
       "99355                               1                         0  \n",
       "890251                              1                         0  \n",
       "745817                              1                         0  \n",
       "421793                              1                         0  \n",
       "...                               ...                       ...  \n",
       "310028                              0                         1  \n",
       "663567                              1                         0  \n",
       "1049160                             1                         0  \n",
       "442785                              0                         0  \n",
       "501372                              1                         0  \n",
       "\n",
       "[86868 rows x 68 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c91e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = predict_from_multiple_estimator(fitted_estimators, label_encoder, [merged_data_test, merged_data_test, test_values], [0.95991211, 0.99814453, 1.0])\n",
    "predictions = predict_from_multiple_estimator(fitted_estimators, label_encoder, [merged_data_test, merged_data_test, test_values], [0.95991211, 0.99814453, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7487e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv(DATA_DIR / 'submission_format.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b99ad783",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame(data=predictions+1,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2033097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300051</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99355</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890251</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745817</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421793</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             damage_grade\n",
       "building_id              \n",
       "300051                  3\n",
       "99355                   2\n",
       "890251                  2\n",
       "745817                  1\n",
       "421793                  3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf92115",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('ensemble_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffee1f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f5a6153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88540434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[0.95991211, 0.99814453],\n",
       "       [0.95993729, 0.99815521],\n",
       "       [0.95984097, 0.9981617 ]]), array([0.2499952, 0.2499952, 0.2499952]))\n",
       "           fun: 0.2499952034688513\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 49\n",
       "           nit: 17\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([0.95991211, 0.99814453])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1609375 , 0.93671875\n",
    "#1.00208333, 1.04965278, 0.99490741"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
